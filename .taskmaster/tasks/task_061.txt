# Task ID: 61
# Title: Phase 4: Optimize Data Processing Pipeline
# Status: pending
# Dependencies: 60
# Priority: high
# Description: Fix the 50K row loading issue and implement smart data querying
# Details:
Stop sending full datasets to OpenAI. Implement query-first approach where DuckDB queries data locally and only sends relevant results (5-10 rows) to AI. Add progressive data loading for large files.

# Test Strategy:


# Subtasks:
## 1. Implement query-first data processing [pending]
### Dependencies: None
### Description: Change data flow to query locally first, then send only results to AI
### Details:
Update api.chat-query.tsx to run DuckDB query first. Extract only top 10-20 relevant rows. Send condensed results to OpenAI instead of full dataset. Reduce payload from 3.5MB to <100KB.

## 2. Implement progressive data loading [pending]
### Dependencies: 61.1
### Description: Add chunked loading for large files to prevent memory issues
### Details:
Update duckdb-service.client.ts to load data in 10K row chunks. Add progress reporting. Yield control between chunks with setTimeout(0) to prevent UI blocking.

## 3. Fix PDF content truncation issue [pending]
### Dependencies: 61.1
### Description: Remove aggressive 30K character limit that loses relevant content
### Details:
Update unified-intelligence.server.ts to remove 30K limit. Implement smart content selection based on relevance scoring. Fix 'Lost in Middle' by using full content with proper chunking.

